# 前后端分离的康复评估系统

## 项目简介

本项目是一个基于前后端分离架构的康复动作评估系统，利用Ultralytics YOLO姿态估计模型实现实时人体姿态识别和康复动作评估。系统支持多种内置康复动作，并允许用户自定义动作配置，适用于康复训练、体育锻炼等场景。

## 技术栈

- **后端**: Python + FastAPI + WebSocket + Ultralytics YOLO
- **前端**: HTML5 + JavaScript + CSS + Canvas + WebSocket

## 项目架构

```
┌─────────────┐      WebSocket      ┌─────────────┐
│   前端网页   │  ╭──────────────────▶  后端服务   │
│  (浏览器)    │  │  视频帧流        │  (FastAPI)  │
│  - 动作选择面板│  │                  │  - YOLO姿态  │
│  - WebSocket │  │  识别结果        │    估计      │
│  - 可视化展示 │◀───────────────────╯  - 动作评估  │
│  - 设置面板   │  │  配置更新        │  - 自定义动作 │
│  - 视频保存功能│  │  动作选择        │    管理      │
└─────────────┘                     └─────────────┘
```

## 核心功能

### 后端功能
- WebSocket服务，处理实时视频流
- YOLO姿态估计模型集成
- 康复动作识别与评估
- 自定义动作管理（添加、保存、加载）
- 实时结果返回

### 前端功能
- 摄像头调用与视频预览
- 动作选择面板（内置动作 + 自定义动作）
- 实时可视化展示
  - 人体骨架绘制
  - 动作角度显示
  - 动作次数计数
  - 动作阶段指示
- 设置面板（置信度、图像大小、线条粗细调整）
- 自定义动作管理
- 视频保存功能

## 快速开始

### 安装依赖

```bash
pip install fastapi uvicorn websockets ultralytics opencv-python
```

### 启动服务

1. **启动后端服务**：

```bash
python backend/app.py
```

2. **启动前端服务**：

```bash
python -m http.server 8080
```

3. **访问应用**：

在浏览器中打开 `http://localhost:8080`

## 项目结构

### 后端结构

```
backend/
├── app.py              # FastAPI应用入口
├── camera.py           # 摄像头处理（后端摄像头模式）
├── websocket.py        # WebSocket处理
├── models/
│   ├── __init__.py
│   ├── action_config.py    # 动作配置管理
│   ├── keypoint_index_map.py  # 关键点索引映射
│   └── rehab_evaluator.py     # 康复动作评估模块
└── data/
    └── action_configs.json    # 动作配置存储
```

### 前端结构

```
frontend/
├── index.html          # 主页面
├── styles.css          # 样式文件
└── scripts/
    ├── main.js         # 主逻辑
    ├── action_selector.js # 动作选择面板
    ├── custom_actions_v2.js # 自定义动作管理
    ├── settings.js     # 设置面板管理
    ├── video_saver.js  # 视频保存功能
    ├── visualization.js # 可视化展示
    ├── websocket.js    # WebSocket通信
```

## 使用说明

### 1. 动作评估流程

1. 打开浏览器访问 `http://localhost:8080`
2. 从下拉菜单中选择要评估的动作（内置动作或自定义动作）
3. 点击"开始评估"按钮
4. 系统开始实时识别和评估动作
5. 观察屏幕上的实时数据：
   - 人体骨架（蓝色线条）
   - 动作名称（大字体显示）
   - 动作次数计数
   - 当前动作阶段（UP/DOWN）
   - 关键角度数值
6. 点击"停止评估"按钮结束评估
7. 可选择保存评估视频

### 2. 自定义动作管理

1. 点击"设置参数"按钮打开设置面板
2. 切换到"自定义动作管理"标签页
3. 点击"添加动作"按钮
4. 填写动作信息：
   - 动作名称
   - 选择三个关键角度点（通过下拉菜单选择）
   - 设置UP角度阈值
   - 设置DOWN角度阈值
5. 点击"保存动作"按钮
6. 新添加的动作将显示在动作选择列表中

### 3. 系统设置

1. 点击"设置参数"按钮打开设置面板
2. 在"基本设置"标签页中调整：
   - 置信度：调整姿态估计的置信度阈值
   - 图像大小：设置视频流的分辨率
   - 线条粗细：调整骨架绘制的线条粗细
3. 设置会实时生效

## 支持的内置动作

- 手臂上举
- 二头肌弯举
- 肩部推举
- 深蹲
- 腿部上举

## 自定义动作配置

自定义动作需要配置以下参数：

- **动作名称**：自定义动作的名称
- **关键点选择**：选择用于计算角度的三个关键点（起点、顶点、终点）
- **UP角度阈值**：动作向上阶段的角度阈值
- **DOWN角度阈值**：动作向下阶段的角度阈值

## 通信协议

系统使用WebSocket进行双向通信，消息格式如下：

### 前端发送消息

```json
{
  "type": "video",
  "data": "base64编码的视频帧",
  "selected_action": "手臂上举"
}
```

### 后端返回消息

```json
{
  "type": "result",
  "action_name": "手臂上举",
  "angle": 120.5,
  "count": 5,
  "stage": "UP",
  "keypoints": [...],
  "status": "success"
}
```

## 部署说明

### 本地部署

1. 确保已安装Python 3.8及以上版本
2. 安装依赖包
3. 启动后端服务
4. 启动前端HTTP服务
5. 在浏览器中访问应用

### 配置说明

- 后端配置：可修改`backend/app.py`中的端口和主机配置
- 前端配置：可修改`frontend/scripts/websocket.js`中的WebSocket连接地址
- 动作配置：存储在`backend/data/action_configs.json`文件中

## 开发计划

1. ✅ 后端开发：FastAPI应用搭建、WebSocket服务、YOLO姿态估计集成
2. ✅ 前端开发：摄像头调用、动作选择、WebSocket通信、可视化展示
3. ✅ 集成测试：前后端联调、功能测试
4. ✅ 本地部署测试：完整流程测试、用户体验测试
5. ⏳ 性能优化：视频压缩、模型优化
6. ⏳ 更多动作支持：扩展内置动作库
7. ⏳ 数据分析功能：训练记录、进度追踪

## 许可证

本项目采用MIT许可证，详见LICENSE文件。

## 致谢

- Ultralytics YOLO：提供强大的姿态估计模型
- FastAPI：高性能的Python Web框架
- 所有贡献者和测试人员

## 联系方式

如有问题或建议，欢迎通过GitHub Issues反馈。
